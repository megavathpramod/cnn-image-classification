{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-17T14:29:50.978258Z",
     "iopub.status.busy": "2025-11-17T14:29:50.977993Z",
     "iopub.status.idle": "2025-11-17T14:30:12.137628Z",
     "shell.execute_reply": "2025-11-17T14:30:12.136823Z",
     "shell.execute_reply.started": "2025-11-17T14:29:50.978237Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting protobuf==4.23.4\n",
      "  Downloading protobuf-4.23.4-cp37-abi3-manylinux2014_x86_64.whl.metadata (540 bytes)\n",
      "Downloading protobuf-4.23.4-cp37-abi3-manylinux2014_x86_64.whl (304 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m304.5/304.5 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: protobuf\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "model-signing 1.1.1 requires typing-extensions, which is not installed.\n",
      "onnx 1.18.0 requires typing_extensions>=4.7.1, which is not installed.\n",
      "google-cloud-aiplatform 1.125.0 requires typing_extensions, which is not installed.\n",
      "opentelemetry-exporter-otlp-proto-http 1.37.0 requires typing-extensions>=4.5.0, which is not installed.\n",
      "bigframes 2.12.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\n",
      "bigframes 2.12.0 requires typing-extensions<5,>=4.5.0, which is not installed.\n",
      "google-generativeai 0.8.5 requires typing-extensions, which is not installed.\n",
      "wandb 0.21.0 requires typing-extensions<5,>=4.8, which is not installed.\n",
      "tensorflow-decision-forests 1.11.0 requires wheel, which is not installed.\n",
      "tensorflow 2.18.0 requires typing-extensions>=3.6.6, which is not installed.\n",
      "orbax-checkpoint 0.11.19 requires typing_extensions, which is not installed.\n",
      "opentelemetry-proto 1.37.0 requires protobuf<7.0,>=5.0, but you have protobuf 4.23.4 which is incompatible.\n",
      "onnx 1.18.0 requires protobuf>=4.25.1, but you have protobuf 4.23.4 which is incompatible.\n",
      "a2a-sdk 0.3.10 requires protobuf>=5.29.5, but you have protobuf 4.23.4 which is incompatible.\n",
      "ray 2.51.1 requires click!=8.3.0,>=7.0, but you have click 8.3.0 which is incompatible.\n",
      "bigframes 2.12.0 requires rich<14,>=12.4.4, but you have rich 14.2.0 which is incompatible.\n",
      "tensorflow-metadata 1.17.2 requires protobuf>=4.25.2; python_version >= \"3.11\", but you have protobuf 4.23.4 which is incompatible.\n",
      "pydrive2 1.21.3 requires cryptography<44, but you have cryptography 46.0.3 which is incompatible.\n",
      "pydrive2 1.21.3 requires pyOpenSSL<=24.2.1,>=19.1.0, but you have pyopenssl 25.3.0 which is incompatible.\n",
      "ydf 0.13.0 requires protobuf<7.0.0,>=5.29.1, but you have protobuf 4.23.4 which is incompatible.\n",
      "grpcio-status 1.71.2 requires protobuf<6.0dev,>=5.26.1, but you have protobuf 4.23.4 which is incompatible.\n",
      "gcsfs 2025.3.0 requires fsspec==2025.3.0, but you have fsspec 2025.10.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed protobuf-4.23.4\n"
     ]
    }
   ],
   "source": [
    "# Uninstall potentially conflicting pre-installed versions (optional, but ensures a clean state)\n",
    "!pip uninstall -qqy protobuf six wheel typing-extensions\n",
    "\n",
    "# Install a compatible version of protobuf\n",
    "# Version 4.23.4 or 3.20.x are often good choices depending on the TF version used in Kaggle\n",
    "!pip install protobuf==4.23.4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-17T14:30:12.139172Z",
     "iopub.status.busy": "2025-11-17T14:30:12.138883Z",
     "iopub.status.idle": "2025-11-17T14:30:28.191666Z",
     "shell.execute_reply": "2025-11-17T14:30:28.190832Z",
     "shell.execute_reply.started": "2025-11-17T14:30:12.139148Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-17 14:30:13.653733: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1763389813.874225      48 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1763389813.927945      48 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.applications.efficientnet_v2 import EfficientNetV2S\n",
    "from tensorflow.keras.applications.efficientnet_v2 import preprocess_input\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from tensorflow.keras.utils import load_img, img_to_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-17T14:30:28.193016Z",
     "iopub.status.busy": "2025-11-17T14:30:28.192500Z",
     "iopub.status.idle": "2025-11-17T14:30:28.196975Z",
     "shell.execute_reply": "2025-11-17T14:30:28.196252Z",
     "shell.execute_reply.started": "2025-11-17T14:30:28.192994Z"
    }
   },
   "outputs": [],
   "source": [
    "IMG_SIZE = (224, 224)  # A good standard size\n",
    "BATCH_SIZE = 32\n",
    "SEED = 42\n",
    "NUM_CLASSES = 10\n",
    "train_dir = \"/kaggle/input/new-paddy-doctor-paddy-disease-classification/paddy-disease-classification/train_images\"\n",
    "test_dir = \"/kaggle/input/new-paddy-doctor-paddy-disease-classification/paddy-disease-classification/test_images\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-17T14:30:28.199388Z",
     "iopub.status.busy": "2025-11-17T14:30:28.198658Z",
     "iopub.status.idle": "2025-11-17T14:30:48.938741Z",
     "shell.execute_reply": "2025-11-17T14:30:48.938108Z",
     "shell.execute_reply.started": "2025-11-17T14:30:28.199363Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 19131 files belonging to 10 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1763389841.163733      48 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13942 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n",
      "I0000 00:00:1763389841.164448      48 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 13942 MB memory:  -> device: 1, name: Tesla T4, pci bus id: 0000:00:05.0, compute capability: 7.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10407 files belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "train_ds = keras.utils.image_dataset_from_directory(\n",
    "    train_dir,\n",
    "    seed=SEED,\n",
    "    image_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE\n",
    ")\n",
    "\n",
    "val_ds = keras.utils.image_dataset_from_directory(\n",
    "    test_dir,\n",
    "    seed=SEED,\n",
    "    image_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE\n",
    ")\n",
    "class_names = train_ds.class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-17T14:30:48.939572Z",
     "iopub.status.busy": "2025-11-17T14:30:48.939386Z",
     "iopub.status.idle": "2025-11-17T14:30:48.966153Z",
     "shell.execute_reply": "2025-11-17T14:30:48.965603Z",
     "shell.execute_reply.started": "2025-11-17T14:30:48.939557Z"
    }
   },
   "outputs": [],
   "source": [
    "data_augmentation = keras.Sequential(\n",
    "  [\n",
    "    layers.RandomFlip(\"horizontal\"),\n",
    "    layers.RandomRotation(0.2),\n",
    "    layers.RandomZoom(0.2),\n",
    "    layers.RandomTranslation(height_factor=0.2, width_factor=0.2),\n",
    "    # --- ADD THESE LINES ---\n",
    "    layers.RandomContrast(0.1),  # Randomly adjust contrast by up to 10%\n",
    "    layers.RandomBrightness(0.1), # Randomly adjust brightness by up to 10%\n",
    "    # -----------------------\n",
    "  ],\n",
    "  name=\"data_augmentation\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-17T14:30:48.967246Z",
     "iopub.status.busy": "2025-11-17T14:30:48.966987Z",
     "iopub.status.idle": "2025-11-17T14:30:49.325985Z",
     "shell.execute_reply": "2025-11-17T14:30:49.325286Z",
     "shell.execute_reply.started": "2025-11-17T14:30:48.967222Z"
    }
   },
   "outputs": [],
   "source": [
    "# Apply augmentation to the training dataset\n",
    "train_ds = train_ds.map(lambda x, y: (data_augmentation(x, training=True), y),\n",
    "                        num_parallel_calls=tf.data.AUTOTUNE)\n",
    "\n",
    "# Apply the EfficientNet-specific preprocessing to BOTH datasets\n",
    "train_ds = train_ds.map(lambda x, y: (preprocess_input(x), y),\n",
    "                        num_parallel_calls=tf.data.AUTOTUNE)\n",
    "val_ds = val_ds.map(lambda x, y: (preprocess_input(x), y),\n",
    "                      num_parallel_calls=tf.data.AUTOTUNE)\n",
    "\n",
    "# Configure datasets for performance\n",
    "train_ds = train_ds.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "val_ds = val_ds.prefetch(buffer_size=tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-17T14:30:49.327043Z",
     "iopub.status.busy": "2025-11-17T14:30:49.326749Z",
     "iopub.status.idle": "2025-11-17T14:30:53.260447Z",
     "shell.execute_reply": "2025-11-17T14:30:53.259840Z",
     "shell.execute_reply.started": "2025-11-17T14:30:49.327020Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/efficientnet_v2/efficientnetv2-s_notop.h5\n",
      "\u001b[1m82420632/82420632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ efficientnetv2-s (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)     │    <span style=\"color: #00af00; text-decoration-color: #00af00\">20,331,360</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">12,810</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_2 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ efficientnetv2-s (\u001b[38;5;33mFunctional\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m1280\u001b[0m)     │    \u001b[38;5;34m20,331,360\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1280\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1280\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │        \u001b[38;5;34m12,810\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">20,344,170</span> (77.61 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m20,344,170\u001b[0m (77.61 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">12,810</span> (50.04 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m12,810\u001b[0m (50.04 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">20,331,360</span> (77.56 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m20,331,360\u001b[0m (77.56 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "base_model = EfficientNetV2S(\n",
    "    include_top=False, \n",
    "    weights='imagenet',   \n",
    "    input_shape=(IMG_SIZE[0], IMG_SIZE[1], 3)\n",
    ")\n",
    "\n",
    "base_model.trainable = False\n",
    "\n",
    "\n",
    "inputs = keras.Input(shape=(IMG_SIZE[0], IMG_SIZE[1], 3))\n",
    "\n",
    "x = base_model(inputs, training=False)\n",
    "\n",
    "x = layers.GlobalAveragePooling2D()(x)\n",
    "x = layers.Dropout(0.5)(x) \n",
    "outputs = layers.Dense(NUM_CLASSES, activation='softmax')(x) # Final 10-class output\n",
    "\n",
    "\n",
    "model_transfer_learning = Model(inputs, outputs)\n",
    "\n",
    "\n",
    "model_transfer_learning.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-17T14:30:53.261345Z",
     "iopub.status.busy": "2025-11-17T14:30:53.261154Z",
     "iopub.status.idle": "2025-11-17T14:30:53.264996Z",
     "shell.execute_reply": "2025-11-17T14:30:53.264272Z",
     "shell.execute_reply.started": "2025-11-17T14:30:53.261328Z"
    }
   },
   "outputs": [],
   "source": [
    "lr_scheduler = keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.2,\n",
    "    patience=1,\n",
    "    min_lr=0.000001\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-17T14:30:53.266385Z",
     "iopub.status.busy": "2025-11-17T14:30:53.266023Z",
     "iopub.status.idle": "2025-11-17T14:30:53.314055Z",
     "shell.execute_reply": "2025-11-17T14:30:53.313442Z",
     "shell.execute_reply.started": "2025-11-17T14:30:53.266361Z"
    }
   },
   "outputs": [],
   "source": [
    "model_transfer_learning.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "    loss='sparse_categorical_crossentropy', # Use this because your labels are integers\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-17T14:30:53.316357Z",
     "iopub.status.busy": "2025-11-17T14:30:53.316152Z",
     "iopub.status.idle": "2025-11-17T15:12:55.790027Z",
     "shell.execute_reply": "2025-11-17T15:12:55.789157Z",
     "shell.execute_reply.started": "2025-11-17T14:30:53.316342Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1763389875.674703     128 service.cc:148] XLA service 0x7b5c600028c0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1763389875.675606     128 service.cc:156]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
      "I0000 00:00:1763389875.675624     128 service.cc:156]   StreamExecutor device (1): Tesla T4, Compute Capability 7.5\n",
      "I0000 00:00:1763389879.811252     128 cuda_dnn.cc:529] Loaded cuDNN version 90300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m  1/598\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7:48:17\u001b[0m 47s/step - accuracy: 0.0625 - loss: 2.4127"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1763389900.247506     128 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m598/598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m255s\u001b[0m 348ms/step - accuracy: 0.2702 - loss: 2.0343 - val_accuracy: 0.4274 - val_loss: 1.5904 - learning_rate: 0.0010\n",
      "Epoch 2/15\n",
      "\u001b[1m598/598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m163s\u001b[0m 272ms/step - accuracy: 0.4272 - loss: 1.6561 - val_accuracy: 0.4550 - val_loss: 1.5434 - learning_rate: 0.0010\n",
      "Epoch 3/15\n",
      "\u001b[1m598/598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m163s\u001b[0m 271ms/step - accuracy: 0.4551 - loss: 1.5699 - val_accuracy: 0.4914 - val_loss: 1.4492 - learning_rate: 0.0010\n",
      "Epoch 4/15\n",
      "\u001b[1m598/598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m161s\u001b[0m 269ms/step - accuracy: 0.4575 - loss: 1.5479 - val_accuracy: 0.4767 - val_loss: 1.4761 - learning_rate: 0.0010\n",
      "Epoch 5/15\n",
      "\u001b[1m598/598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m162s\u001b[0m 270ms/step - accuracy: 0.4742 - loss: 1.5255 - val_accuracy: 0.4991 - val_loss: 1.4323 - learning_rate: 2.0000e-04\n",
      "Epoch 6/15\n",
      "\u001b[1m598/598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m164s\u001b[0m 273ms/step - accuracy: 0.4706 - loss: 1.5230 - val_accuracy: 0.4971 - val_loss: 1.4340 - learning_rate: 2.0000e-04\n",
      "Epoch 7/15\n",
      "\u001b[1m598/598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m162s\u001b[0m 271ms/step - accuracy: 0.4692 - loss: 1.5139 - val_accuracy: 0.4971 - val_loss: 1.4301 - learning_rate: 4.0000e-05\n",
      "Epoch 8/15\n",
      "\u001b[1m598/598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m161s\u001b[0m 268ms/step - accuracy: 0.4792 - loss: 1.5024 - val_accuracy: 0.5000 - val_loss: 1.4219 - learning_rate: 4.0000e-05\n",
      "Epoch 9/15\n",
      "\u001b[1m598/598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m163s\u001b[0m 271ms/step - accuracy: 0.4838 - loss: 1.4864 - val_accuracy: 0.4945 - val_loss: 1.4315 - learning_rate: 4.0000e-05\n",
      "Epoch 10/15\n",
      "\u001b[1m598/598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m163s\u001b[0m 272ms/step - accuracy: 0.4727 - loss: 1.5170 - val_accuracy: 0.4947 - val_loss: 1.4308 - learning_rate: 8.0000e-06\n",
      "Epoch 11/15\n",
      "\u001b[1m598/598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 266ms/step - accuracy: 0.4825 - loss: 1.4986 - val_accuracy: 0.4941 - val_loss: 1.4311 - learning_rate: 1.6000e-06\n",
      "Epoch 12/15\n",
      "\u001b[1m598/598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m162s\u001b[0m 270ms/step - accuracy: 0.4750 - loss: 1.5003 - val_accuracy: 0.4941 - val_loss: 1.4311 - learning_rate: 1.0000e-06\n",
      "Epoch 13/15\n",
      "\u001b[1m598/598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m162s\u001b[0m 269ms/step - accuracy: 0.4763 - loss: 1.5060 - val_accuracy: 0.4938 - val_loss: 1.4310 - learning_rate: 1.0000e-06\n",
      "Epoch 14/15\n",
      "\u001b[1m598/598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 265ms/step - accuracy: 0.4780 - loss: 1.5016 - val_accuracy: 0.4940 - val_loss: 1.4311 - learning_rate: 1.0000e-06\n",
      "Epoch 15/15\n",
      "\u001b[1m598/598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m162s\u001b[0m 270ms/step - accuracy: 0.4701 - loss: 1.5051 - val_accuracy: 0.4940 - val_loss: 1.4312 - learning_rate: 1.0000e-06\n"
     ]
    }
   ],
   "source": [
    "history = model_transfer_learning.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=15,\n",
    "    callbacks=[lr_scheduler]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-17T15:21:09.644118Z",
     "iopub.status.busy": "2025-11-17T15:21:09.643538Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Recompiling model for Fine-Tuning ---\n",
      "--- Starting Phase 2: Fine-Tuning (Unfrozen Top Layers) ---\n",
      "Epoch 16/70\n",
      "\u001b[1m598/598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m275s\u001b[0m 363ms/step - accuracy: 0.4422 - loss: 1.5993 - val_accuracy: 0.5311 - val_loss: 1.3659 - learning_rate: 1.0000e-05\n",
      "Epoch 17/70\n",
      "\u001b[1m598/598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m162s\u001b[0m 270ms/step - accuracy: 0.5256 - loss: 1.3734 - val_accuracy: 0.5700 - val_loss: 1.2584 - learning_rate: 1.0000e-05\n",
      "Epoch 18/70\n",
      "\u001b[1m598/598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m162s\u001b[0m 270ms/step - accuracy: 0.5716 - loss: 1.2497 - val_accuracy: 0.5908 - val_loss: 1.1913 - learning_rate: 1.0000e-05\n",
      "Epoch 19/70\n",
      "\u001b[1m598/598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m162s\u001b[0m 269ms/step - accuracy: 0.6031 - loss: 1.1633 - val_accuracy: 0.6269 - val_loss: 1.0985 - learning_rate: 1.0000e-05\n",
      "Epoch 20/70\n",
      "\u001b[1m598/598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m163s\u001b[0m 271ms/step - accuracy: 0.6204 - loss: 1.1000 - val_accuracy: 0.6486 - val_loss: 1.0418 - learning_rate: 1.0000e-05\n",
      "Epoch 21/70\n",
      "\u001b[1m598/598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m165s\u001b[0m 274ms/step - accuracy: 0.6498 - loss: 1.0350 - val_accuracy: 0.6724 - val_loss: 0.9791 - learning_rate: 1.0000e-05\n",
      "Epoch 22/70\n",
      "\u001b[1m598/598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m164s\u001b[0m 272ms/step - accuracy: 0.6740 - loss: 0.9645 - val_accuracy: 0.6825 - val_loss: 0.9486 - learning_rate: 1.0000e-05\n",
      "Epoch 23/70\n",
      "\u001b[1m598/598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m164s\u001b[0m 273ms/step - accuracy: 0.6858 - loss: 0.9228 - val_accuracy: 0.6906 - val_loss: 0.9241 - learning_rate: 1.0000e-05\n",
      "Epoch 24/70\n",
      "\u001b[1m598/598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m163s\u001b[0m 272ms/step - accuracy: 0.6988 - loss: 0.8838 - val_accuracy: 0.7075 - val_loss: 0.8795 - learning_rate: 1.0000e-05\n",
      "Epoch 25/70\n",
      "\u001b[1m598/598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 217ms/step - accuracy: 0.7189 - loss: 0.8274"
     ]
    }
   ],
   "source": [
    "# NEW CELL: Phase 2 - Fine-Tuning Setup\n",
    "\n",
    "# 1. Unfreeze the base model\n",
    "base_model.trainable = True\n",
    "\n",
    "# 2. Freeze all but the last 30 layers \n",
    "# (Layers 0 to N-31 are frozen; the top 30 are trainable)\n",
    "for layer in base_model.layers[:-80]:\n",
    "    layer.trainable = False\n",
    "\n",
    "# 3. Recompile the model with a very low learning rate\n",
    "print(\"--- Recompiling model for Fine-Tuning ---\")\n",
    "model_transfer_learning.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.00001), # CRITICAL: Very low LR\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# 4. Continue training for another 15 epochs \n",
    "print(\"--- Starting Phase 2: Fine-Tuning (Unfrozen Top Layers) ---\")\n",
    "history_2 = model_transfer_learning.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=70, # Total target epochs (15 initial + 15 fine-tune)\n",
    "    initial_epoch=history.epoch[-1] + 1, # <--- CORRECTED: Changed history_1 to history\n",
    "    callbacks=[lr_scheduler]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-17T15:13:23.632023Z",
     "iopub.status.busy": "2025-11-17T15:13:23.631404Z",
     "iopub.status.idle": "2025-11-17T15:14:08.474416Z",
     "shell.execute_reply": "2025-11-17T15:14:08.473789Z",
     "shell.execute_reply.started": "2025-11-17T15:13:23.632001Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Running final evaluation on validation set ---\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 111ms/step - accuracy: 0.5016 - loss: 1.4258\n",
      "\n",
      "Final Validation Loss: 1.4312\n",
      "Final Validation Accuracy: 49.40%\n"
     ]
    }
   ],
   "source": [
    "## NEW CELL: Final Evaluation\n",
    "\n",
    "print(\"--- Running final evaluation on validation set ---\")\n",
    "# Evaluate on the validation dataset (val_ds)\n",
    "loss, acc = model_transfer_learning.evaluate(val_ds, verbose=1)\n",
    "\n",
    "print(f\"\\nFinal Validation Loss: {loss:.4f}\")\n",
    "print(f\"Final Validation Accuracy: {acc*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-17T15:14:53.305489Z",
     "iopub.status.busy": "2025-11-17T15:14:53.305225Z",
     "iopub.status.idle": "2025-11-17T15:16:17.971610Z",
     "shell.execute_reply": "2025-11-17T15:16:17.970893Z",
     "shell.execute_reply.started": "2025-11-17T15:14:53.305472Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collected 10407 total validation images and labels.\n",
      "--- Generating Predictions on Reconstructed Validation Data ---\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 128ms/step\n",
      "\n",
      "--- Corrected Detailed Classification Report (Final Model) ---\n",
      "                          precision    recall  f1-score   support\n",
      "\n",
      "   bacterial_leaf_blight       0.36      0.23      0.28       479\n",
      "   bacterial_leaf_streak       0.32      0.40      0.36       380\n",
      "bacterial_panicle_blight       0.60      0.79      0.68       337\n",
      "                   blast       0.69      0.41      0.52      1738\n",
      "              brown_spot       0.26      0.76      0.38       965\n",
      "              dead_heart       0.91      0.67      0.77      1442\n",
      "            downy_mildew       0.34      0.46      0.39       620\n",
      "                   hispa       0.67      0.23      0.34      1594\n",
      "                  normal       0.54      0.76      0.63      1764\n",
      "                  tungro       0.59      0.19      0.29      1088\n",
      "\n",
      "                accuracy                           0.49     10407\n",
      "               macro avg       0.53      0.49      0.46     10407\n",
      "            weighted avg       0.59      0.49      0.49     10407\n",
      "\n",
      "\n",
      "Overall Accuracy Check (from Report Data): 49.40%\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import classification_report\n",
    "import tensorflow as tf\n",
    "\n",
    "# 1. Collect all images and labels into sequential NumPy arrays\n",
    "X_test = []\n",
    "Y_true = []\n",
    "\n",
    "# Iterate over a clean, unbatched version of the validation dataset to ensure order\n",
    "for image, label in val_ds.unbatch().as_numpy_iterator():\n",
    "    X_test.append(image)\n",
    "    Y_true.append(label)\n",
    "\n",
    "X_test = np.array(X_test)\n",
    "Y_true = np.array(Y_true)\n",
    "\n",
    "print(f\"Collected {len(X_test)} total validation images and labels.\")\n",
    "\n",
    "# 2. Make predictions on the collected NumPy array\n",
    "# This ensures the predictions match the order of Y_true\n",
    "print(\"--- Generating Predictions on Reconstructed Validation Data ---\")\n",
    "Y_pred_probabilities = model_transfer_learning.predict(X_test)\n",
    "Y_pred_classes = np.argmax(Y_pred_probabilities, axis=1)\n",
    "\n",
    "# 3. Print the final, corrected classification report\n",
    "print(\"\\n--- Corrected Detailed Classification Report (Final Model) ---\")\n",
    "print(classification_report(Y_true, Y_pred_classes, target_names=class_names))\n",
    "\n",
    "# 4. Final Sanity Check\n",
    "accuracy_check = np.mean(Y_pred_classes == Y_true) * 100\n",
    "print(f\"\\nOverall Accuracy Check (from Report Data): {accuracy_check:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-17T15:16:17.973167Z",
     "iopub.status.busy": "2025-11-17T15:16:17.972814Z",
     "iopub.status.idle": "2025-11-17T15:16:18.005274Z",
     "shell.execute_reply": "2025-11-17T15:16:18.004310Z",
     "shell.execute_reply.started": "2025-11-17T15:16:17.973148Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history_1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_48/1043903676.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Combine metrics from both phases\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory_1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mhistory_2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mval_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory_1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_accuracy'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mhistory_2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory_1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mhistory_2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'history_1' is not defined"
     ]
    }
   ],
   "source": [
    "# Cell 11: Modified Plotting Code\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Combine metrics from both phases\n",
    "acc = history_1.history['accuracy'] + history_2.history['accuracy']\n",
    "val_acc = history_1.history['val_accuracy'] + history_2.history['val_accuracy']\n",
    "loss = history_1.history['loss'] + history_2.history['loss']\n",
    "val_loss = history_1.history['val_loss'] + history_2.history['val_loss']\n",
    "\n",
    "# Plot Accuracy\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.plot(acc, label='Training Accuracy')\n",
    "plt.plot(val_acc, label='Validation Accuracy')\n",
    "plt.title('Combined Model Accuracy (Feature Extraction + Fine-Tuning)')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.axvline(x=15, color='r', linestyle='--', label='Fine-Tuning Starts') # Mark the transition\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Plot Loss\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.plot(loss, label='Training Loss')\n",
    "plt.plot(val_loss, label='Validation Loss')\n",
    "plt.title('Combined Model Loss (Feature Extraction + Fine-Tuning)')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.axvline(x=15, color='r', linestyle='--', label='Fine-Tuning Starts')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-11-17T15:13:12.689946Z",
     "iopub.status.idle": "2025-11-17T15:13:12.690158Z",
     "shell.execute_reply": "2025-11-17T15:13:12.690069Z",
     "shell.execute_reply.started": "2025-11-17T15:13:12.690060Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "model_transfer_learning.save('my_trained_model.keras')\n",
    "print(\"Model successfully saved to 'my_trained_model.keras'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-11-17T15:13:12.691247Z",
     "iopub.status.idle": "2025-11-17T15:13:12.691478Z",
     "shell.execute_reply": "2025-11-17T15:13:12.691371Z",
     "shell.execute_reply.started": "2025-11-17T15:13:12.691362Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Load the saved model\n",
    "loaded_model = load_model('my_trained_model.keras') # Or 'my_trained_model.h5'\n",
    "\n",
    "# Verify the model architecture (optional)\n",
    "loaded_model.summary()\n",
    "\n",
    "# The model is now ready to be used!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-11-17T15:13:12.692720Z",
     "iopub.status.idle": "2025-11-17T15:13:12.692972Z",
     "shell.execute_reply": "2025-11-17T15:13:12.692848Z",
     "shell.execute_reply.started": "2025-11-17T15:13:12.692838Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.save(\"class_names.npy\", class_names)\n",
    "\n",
    "print(\"Model and class names saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-11-17T15:13:12.694362Z",
     "iopub.status.idle": "2025-11-17T15:13:12.694654Z",
     "shell.execute_reply": "2025-11-17T15:13:12.694496Z",
     "shell.execute_reply.started": "2025-11-17T15:13:12.694482Z"
    }
   },
   "outputs": [],
   "source": [
    "!pip install gradio\n",
    "\n",
    "import gradio as gr\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "from tensorflow.keras.applications.efficientnet_v2 import preprocess_input\n",
    " \n",
    "\n",
    "model = tf.keras.models.load_model(\"my_paddy_model.keras\")\n",
    "\n",
    "class_names = np.load(\"class_names.npy\", allow_pickle=True)\n",
    "\n",
    "def predict_image(pil_image):\n",
    "   \n",
    "    img = pil_image.resize((224, 224))\n",
    "    \n",
    "    \n",
    "    img_array = tf.keras.preprocessing.image.img_to_array(img)\n",
    "    \n",
    "    img_batch = np.expand_dims(img_array, axis=0)\n",
    "    \n",
    "    processed_image = preprocess_input(img_batch)\n",
    "    \n",
    "    \n",
    "    prediction = model.predict(processed_image)\n",
    "    \n",
    "    scores = prediction[0]\n",
    "    \n",
    "    confidences = {class_names[i]: float(scores[i]) for i in range(len(class_names))}\n",
    "    \n",
    "    return confidences\n",
    "\n",
    "iface = gr.Interface(\n",
    "    fn=predict_image,\n",
    "    inputs=gr.Image(type=\"pil\", label=\"Upload Paddy Leaf Image\"),\n",
    "    outputs=gr.Label(num_top_classes=3, label=\"Top Predictions\"),\n",
    "    title=\"Paddy Disease Classifier\",\n",
    "    description=\"Upload an image of a paddy leaf to classify the disease. This model uses an EfficientNetV2S base.\"\n",
    ")\n",
    "\n",
    "iface.launch(share=True)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 4945122,
     "sourceId": 8325727,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31193,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
